{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81c14b5a-cb3a-46a3-9ad4-9a0af94f6f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# with pip\n",
    "%pip install --upgrade --quiet  supabase langchain langchain_community langchain_core langchain_openai pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b490ec3-93c3-4cce-9dc2-6c95ee9f5917",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import SupabaseVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from glob import glob\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# âœ… Load .env variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa62993f-b169-410f-8c2a-954930c6ebc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from supabase import create_client, Client\n",
    "\n",
    "# âœ… Supabase setup\n",
    "SUPABASE_URL = os.getenv(\"SUPABASE_URL\")\n",
    "SUPABASE_KEY = os.getenv(\"SUPABASE_KEY\")\n",
    "supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a95200-2cb6-4521-950a-44ce54a263c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Config\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")  # your OpenAI key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dea09b96-bc79-4813-85d3-03a781512cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Initialize embeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88cc8e0e-4dc8-4abd-bd7b-afc27e931ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Folder containing PDFs\n",
    "pdf_folder = \"dataset/*.pdf\"\n",
    "pdf_files = glob(pdf_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "632cc414-a1ca-4645-8267-605ee49f021e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Processing: 2412.00857v2.pdf\n",
      "ðŸ“„ Processing: 2502.11880v1.pdf\n",
      "ðŸ“„ Processing: 2504.08791v1.pdf\n",
      "ðŸ“„ Processing: 2504.11289v1.pdf\n",
      "ðŸ“„ Processing: 2504.12626v2.pdf\n",
      "ðŸ“„ Processing: lstm.pdf\n",
      "ðŸ“„ Processing: vnet.pdf\n",
      "âœ… All PDFs processed and stored in Supabase!\n"
     ]
    }
   ],
   "source": [
    "# âœ… Loop over PDFs\n",
    "for pdf_path in pdf_files:\n",
    "    file_name = os.path.basename(pdf_path)\n",
    "    print(f\"ðŸ“„ Processing: {file_name}\")\n",
    "\n",
    "    # 1. Insert metadata into `documents`\n",
    "    doc_record = supabase.table(\"documents\").insert({\"title\": file_name}).execute()\n",
    "    document_id = doc_record.data[0][\"id\"]\n",
    "\n",
    "    # 2. Load and chunk PDF\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    docs = loader.load()\n",
    "\n",
    "    # Remove null characters and other problematic control characters\n",
    "    def clean_text(text):\n",
    "        return text.replace(\"\\u0000\", \"\").replace(\"\\x00\", \"\")\n",
    "    \n",
    "    # 3. Attach document_id to metadata of each chunk\n",
    "    for d in docs:\n",
    "        d.page_content = clean_text(d.page_content)  # âœ… clean chunk content\n",
    "        d.metadata[\"document_id\"] = document_id\n",
    "\n",
    "    # 4. Store chunks + embeddings\n",
    "    vector_store = SupabaseVectorStore.from_documents(\n",
    "        docs,\n",
    "        embeddings,\n",
    "        client=supabase,\n",
    "        table_name=\"chunks\",\n",
    "        query_name=\"match_chunks\"\n",
    "    )\n",
    "\n",
    "print(\"âœ… All PDFs processed and stored in Supabase!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffaf3a8-9a61-4107-b1b1-afaaab535929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bbbc98-3649-4da5-b44d-a1e217fd291c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Step 4. Query and Get Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7e692d41-e1b3-440b-951c-2034b3b87399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– Answer:\n",
      " LSTM stands for Long Short-Term Memory, which is a type of Recurrent Neural Network (RNN) designed to effectively learn from sequences of data over long periods of time. LSTMs are particularly useful for tasks that involve time series data or sequences, such as speech recognition, handwriting recognition, and machine translation. They address the limitations of standard RNNs, particularly the vanishing and exploding gradient problems, allowing them to retain information over longer time intervals (more than 1,000 timesteps). LSTMs achieve this through special memory cells and gating mechanisms that control the flow of information.\n",
      "\n",
      "ðŸ“š Sources Used:\n",
      "- dataset\\lstm.pdf\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\",   # Stuff all retrieved docs into context\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "query = \"What is lstm\"\n",
    "result = qa_chain({\"query\": query})\n",
    "# Extract the answer\n",
    "answer = result[\"result\"]\n",
    "# Extract sources\n",
    "sources = {doc.metadata.get(\"source\") for doc in result[\"source_documents\"]}\n",
    "sources = [s for s in sources if s]\n",
    "\n",
    "print(\"ðŸ¤– Answer:\\n\", answer)\n",
    "print(\"\\nðŸ“š Sources Used:\")\n",
    "for s in sources:\n",
    "    print(\"-\", s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19001d06-efea-4b53-ad09-fa432e4922d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
